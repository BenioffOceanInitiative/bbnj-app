---
title: "data_prep"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Get HexIDs for High Seas

- [h3](https://crazycapivara.github.io/h3-r/articles/h3.html)

- [bbnj::p_abnj](https://benioffoceaninitiative.github.io/bbnj/reference/p_abnj.html)
- https://github.com/crazycapivara/h3-r/blob/master/inst/examples/nc-polyfill.R

- [h3:polyfill](https://crazycapivara.github.io/h3-r/reference/polyfill.html)\
  Get all hexagons with centers contained in a given polygon\
  `hex_ids <- polyfill(bbnj::p_abnj)`
  https://crazycapivara.github.io/h3-r/reference/polyfill.html 
  
- [h3::h3_set_to_multi_polygon](https://crazycapivara.github.io/h3-r/reference/h3_set_to_multi_polygon.html)\
  Create a (multi) polygon describing the outline(s) of a set of hexagons
  `hex_sf <- h3::h3_set_to_multi_polygon(hex_ids)`
  analyze existing raster layers with these to populate planning units and features for prioritizr

```{r}
# install.packages("crazycapivara/h3-r")
librarian::shelf(
  BenioffOceanInitiative/bbnj,
  deckgl, dplyr, geojsonsf, glue, here, jsonlite,
  crazycapivara/h3, leaflet, sf)
```
```{r}
# get polygons for ABNJ (outside EEZ)
abnj <- bbnj::p_abnj

# url prep
# hex_res     <- 2
hex_res     <- 3
hex_compact <- F
hex         <- glue("abnj_hex_res{hex_res}{ifelse(hex_compact, 'c','')}")
hex_geojson <- glue(here("data/{hex}.geojson"))
hexids_www  <- here(glue("www/{hex}.json"))
hexids_url  <- glue("https://shiny.ecoquants.com/bbnj-app/{hex}.json")

# get hexagon IDs for ABNJ polygons
hexids      <- h3::polyfill(abnj, res = hex_res) 
if (hex_compact){
  hexids_c    <- h3::compact(hexids)
  glue("h3 abnj res{hex_res} compact: {length(hexids)} -> {length(hexids_c)}")
  # h3 abnj res2 compact: 2339 -> 1529
  hexids <- hex_ids_c
}
```

## mapping prep

```{r}
# convert hexids to json
hexids_js   <- jsonlite::toJSON(list(list(
  abnj = unbox(1),
  hexIds = hexids)))

# write hexids json file to www folder
writeLines(hexids_js, hexids_www)

```

## prioritizr prep

```{r}
# create multipolygon describing outline of hexagons (for prioritizr)
hex_sf <- h3::h3_set_to_multi_polygon(hex_ids) 
hex_gj <- geojsonsf::sfc_geojson(hex_sf)

# write sfc polygon geojson to data folder
writeLines(hex_gj, hex_geojson)

```

## map `hex_sf` with `leaflet`

```{r}
# works with leaflet , though maybe CRS is off?
leaflet(data = hex_sf, width = "100%") %>% 
  addProviderTiles("Stamen.Toner") %>% 
  addPolygons(
    # weight = 2,
    color = "white",
    fillColor = "white",
    fillOpacity = 0.7)
```

## map `hex_ids` with `deckgl`

```{r}
# hexids_url  <- glue("https://shiny.ecoquants.com/bbnj-app/{hex}.json")
hexids_url <- "https://shiny.ecoquants.com/bbnj-app/abnj_hex_res2.json"
# or use `hexids_js` to test

properties <- list(
  stroked     = TRUE,
  filled      = TRUE,
  extruded    = FALSE,
  getHexagons = ~hexIds,
  # getFillColor = JS("d => [255, (1 - d.abnj / 500) * 255, 0]"),
  getFillColor = c(62,  136, 62),
  getLineColor = c(255, 255, 255),
  lineWidthMinPixels = 1,
  opacity = 0.4
  # ,
  # getTooltip = ~abnj
)

# with res2
deckgl(zoom = 0, pitch = 0) %>%
  # add_h3_cluster_layer(data = hexids_url, properties = properties) %>%
  add_h3_cluster_layer(data = hexids_js, properties = properties) %>%
  add_basemap()

# reading from internal json works, reading from url doesn't yet



```

### sf example

```{r}
# sample_data <- jsonlite::fromJSON(data_url, simplifyDataFrame = FALSE)
sf_json <- "https://raw.githubusercontent.com/uber-common/deck.gl-data/master/website/sf.h3clusters.json"

properties <- list(
  stroked = TRUE,
  filled = TRUE,
  extruded = FALSE,
  getHexagons = ~hexIds,
  getFillColor = JS("d => [255, (1 - d.mean / 500) * 255, 0]"),
  getLineColor = c(255, 255, 255),
  lineWidthMinPixels = 2,
  getTooltip = ~mean
)

deckgl(zoom = 10.5, pitch = 20) %>%
  add_h3_cluster_layer(data = sf_json, properties = properties) %>%
  add_basemap()
```